{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b1aea60",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "LJyAwYgm2YYD",
      "metadata": {
        "id": "LJyAwYgm2YYD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from statistics import mode\n",
        "from collections import Counter, defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf74a65",
      "metadata": {},
      "source": [
        "# Compiled Metrics Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c71456b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price Prediction Target 1 Done\n",
            "Price Prediction Target 5 Done\n",
            "Price Prediction Target 10 Done\n",
            "Price Prediction Target 20 Done\n",
            "Price Prediction Target 50 Done\n",
            "Deep Learning Target 1 Done\n",
            "Deep Learning Target 5 Done\n",
            "Deep Learning Target 10 Done\n",
            "Deep Learning Target 20 Done\n",
            "Deep Learning Target 50 Done\n",
            "Machine Learning Target 1 Done\n",
            "Machine Learning Target 5 Done\n",
            "Machine Learning Target 10 Done\n",
            "Machine Learning Target 20 Done\n",
            "Machine Learning Target 50 Done\n"
          ]
        }
      ],
      "source": [
        "# calculate RMSE\n",
        "modes = ['LSTM' ,'GRU','RNN']\n",
        "EMITEN = 'TLKM'\n",
        "TARGET_DAYS = [1, 5, 10, 20, 50]\n",
        "MODEL_LIST = ['Price Prediction', 'Deep Learning', 'Machine Learning']\n",
        "\n",
        "ensemble_results_dir = f'Ensemble Result/{EMITEN}'\n",
        "if not os.path.exists(ensemble_results_dir):\n",
        "    os.makedirs(ensemble_results_dir)\n",
        "\n",
        "result_file_path = f'{ensemble_results_dir}/{EMITEN}_Results.csv'\n",
        "header_results = f'emiten,model_type,target_day,accuracy,precision,recall,f1_score'\n",
        "with open(result_file_path, 'w') as writer:\n",
        "    writer.write(f'{header_results}\\n')\n",
        "\n",
        "all_predictions = []\n",
        "model_accuracies = {}\n",
        "\n",
        "for MODEL in MODEL_LIST:\n",
        "    for TARGET_DAY in TARGET_DAYS:\n",
        "        if MODEL == 'Price Prediction':\n",
        "            data_path = f'Result {MODEL}/{EMITEN}/LSTM_{EMITEN}_Target_{TARGET_DAY}.csv'\n",
        "        else:\n",
        "            data_path = f'Result {MODEL}/{EMITEN}/{EMITEN}_Target_{TARGET_DAY}.csv'\n",
        "    \n",
        "        result_df = pd.read_csv(data_path)\n",
        "        test_df = result_df[result_df['type'] == 'test']\n",
        "        testCategoryPredict = test_df['prediction'].values\n",
        "        testCatY = test_df['ground_truth'].values\n",
        "\n",
        "        test_acc = round(accuracy_score(list(testCatY), testCategoryPredict), 4)\n",
        "        test_prec = round(precision_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "        test_rec = round(recall_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "        test_f1 = round(f1_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "\n",
        "        test_results = f'{EMITEN},{MODEL},{TARGET_DAY},{test_acc},{test_prec},{test_rec},{test_f1}'\n",
        "\n",
        "        with open(result_file_path, 'a') as writer:\n",
        "            writer.write('{}\\n'.format(test_results))\n",
        "        all_predictions.append(testCategoryPredict)\n",
        "        model_accuracies[(MODEL, TARGET_DAY)] = test_acc\n",
        "        print(f'{MODEL} Target {TARGET_DAY} Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5791861f",
      "metadata": {},
      "source": [
        "### Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "fb77e9ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "total_ensemble = len(TARGET_DAYS)\n",
        "ensemble_preds = np.zeros([all_predictions[0].shape[0], total_ensemble])\n",
        "ensemble_preds.shape\n",
        "\n",
        "np_all_prediction = all_predictions[0]\n",
        "np_all_prediction = np_all_prediction.reshape([-1, 1])\n",
        "\n",
        "## concat all prediction\n",
        "for preds in all_predictions[1:]:\n",
        "    np_all_prediction = np.hstack((np_all_prediction, preds.reshape([-1, 1])))\n",
        "\n",
        "# concat prediction for same targe dat\n",
        "for i in range(total_ensemble):\n",
        "    for j in range(np_all_prediction.shape[0]):\n",
        "        target = 'None'\n",
        "        tmp = np_all_prediction[j]\n",
        "        \n",
        "        # find prediction for the same target day\n",
        "        tmp = (tmp[i + (total_ensemble * 0)], tmp[i + (total_ensemble * 1)], tmp[i + total_ensemble * 2])\n",
        "        label = Counter(tmp).most_common()[0]\n",
        "        if label[1] == 1:\n",
        "            label = 1\n",
        "        else:\n",
        "            label = label[0]\n",
        "        ensemble_preds[j, i] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "0a4f229a",
      "metadata": {},
      "outputs": [],
      "source": [
        "result_df = pd.read_csv(data_path)\n",
        "for i in range(total_ensemble):\n",
        "    result_df = pd.read_csv(data_path)\n",
        "    test_df = result_df[result_df['type'] == 'test']\n",
        "    testCatY = test_df['ground_truth'].values\n",
        "    testCategoryPredict = ensemble_preds[:, i]\n",
        "\n",
        "    test_acc = round(accuracy_score(list(testCatY), testCategoryPredict), 4)\n",
        "    test_prec = round(precision_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "    test_rec = round(recall_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "    test_f1 = round(f1_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "\n",
        "    test_results = f'{EMITEN},Ensemble Model,{TARGET_DAYS[i]},{test_acc},{test_prec},{test_rec},{test_f1}'\n",
        "\n",
        "    with open(result_file_path, 'a') as writer:\n",
        "        writer.write('{}\\n'.format(test_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b81e132d",
      "metadata": {},
      "source": [
        "### Weighted Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "eac49a38",
      "metadata": {},
      "outputs": [],
      "source": [
        "weighted_ensemble_preds = np.zeros([all_predictions[0].shape[0], total_ensemble])\n",
        "weighted_ensemble_preds.shape\n",
        "\n",
        "# Weighted ensemble prediction based on weighted sum\n",
        "for i in range(total_ensemble):\n",
        "    for j in range(np_all_prediction.shape[0]):\n",
        "        class_weight_sum = defaultdict(float) \n",
        "\n",
        "        for k, MODEL in enumerate(MODEL_LIST):\n",
        "            pred_class = np_all_prediction[j, i + (total_ensemble * k)]\n",
        "            weight = model_accuracies[(MODEL, TARGET_DAYS[i])]\n",
        "            class_weight_sum[pred_class] += weight\n",
        "\n",
        "        final_prediction = max(class_weight_sum, key=class_weight_sum.get)\n",
        "        weighted_ensemble_preds[j, i] = final_prediction\n",
        "        \n",
        "result_df = pd.read_csv(data_path)\n",
        "for i in range(total_ensemble):\n",
        "    result_df = pd.read_csv(data_path)\n",
        "    test_df = result_df[result_df['type'] == 'test']\n",
        "    testCatY = test_df['ground_truth'].values\n",
        "    testCategoryPredict = weighted_ensemble_preds[:, i]\n",
        "\n",
        "    test_acc = round(accuracy_score(list(testCatY), testCategoryPredict), 4)\n",
        "    test_prec = round(precision_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "    test_rec = round(recall_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "    test_f1 = round(f1_score(list(testCatY), testCategoryPredict, average='weighted', zero_division=0), 4)\n",
        "\n",
        "    test_results = f'{EMITEN},Weighted Ensemble,{TARGET_DAYS[i]},{test_acc},{test_prec},{test_rec},{test_f1}'\n",
        "\n",
        "    with open(result_file_path, 'a') as writer:\n",
        "        writer.write('{}\\n'.format(test_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3ef09e45",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emiten</th>\n",
              "      <th>model_type</th>\n",
              "      <th>target_day</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Price Prediction</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>0.4138</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>0.5012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Price Prediction</td>\n",
              "      <td>5</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>0.4686</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>0.5289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Price Prediction</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8238</td>\n",
              "      <td>0.7434</td>\n",
              "      <td>0.8238</td>\n",
              "      <td>0.7799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Price Prediction</td>\n",
              "      <td>20</td>\n",
              "      <td>0.9016</td>\n",
              "      <td>0.8595</td>\n",
              "      <td>0.9016</td>\n",
              "      <td>0.8679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Price Prediction</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9098</td>\n",
              "      <td>0.9115</td>\n",
              "      <td>0.9098</td>\n",
              "      <td>0.9034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6107</td>\n",
              "      <td>0.4594</td>\n",
              "      <td>0.6107</td>\n",
              "      <td>0.5052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>5</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.6398</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.6359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9262</td>\n",
              "      <td>0.9234</td>\n",
              "      <td>0.9262</td>\n",
              "      <td>0.9243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>20</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9395</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9016</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>0.9016</td>\n",
              "      <td>0.9052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6393</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.6393</td>\n",
              "      <td>0.5099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>5</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.6933</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.5396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8402</td>\n",
              "      <td>0.7427</td>\n",
              "      <td>0.8402</td>\n",
              "      <td>0.7855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>20</td>\n",
              "      <td>0.9221</td>\n",
              "      <td>0.9229</td>\n",
              "      <td>0.9221</td>\n",
              "      <td>0.9046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9139</td>\n",
              "      <td>0.9166</td>\n",
              "      <td>0.9139</td>\n",
              "      <td>0.9108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Ensemble Model</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.5679</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.6464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Ensemble Model</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.6441</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.6581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Ensemble Model</td>\n",
              "      <td>10</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.7717</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Ensemble Model</td>\n",
              "      <td>20</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6907</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Ensemble Model</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9361</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Weighted Ensemble</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.5679</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.6464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Weighted Ensemble</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.6465</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.6596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Weighted Ensemble</td>\n",
              "      <td>10</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Weighted Ensemble</td>\n",
              "      <td>20</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6907</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.6897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>TLKM</td>\n",
              "      <td>Weighted Ensemble</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9361</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>0.9339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emiten         model_type  target_day  accuracy  precision  recall  \\\n",
              "0    TLKM   Price Prediction           1    0.6352     0.4138  0.6352   \n",
              "1    TLKM   Price Prediction           5    0.6352     0.4686  0.6352   \n",
              "2    TLKM   Price Prediction          10    0.8238     0.7434  0.8238   \n",
              "3    TLKM   Price Prediction          20    0.9016     0.8595  0.9016   \n",
              "4    TLKM   Price Prediction          50    0.9098     0.9115  0.9098   \n",
              "5    TLKM      Deep Learning           1    0.6107     0.4594  0.6107   \n",
              "6    TLKM      Deep Learning           5    0.6598     0.6398  0.6598   \n",
              "7    TLKM      Deep Learning          10    0.9262     0.9234  0.9262   \n",
              "8    TLKM      Deep Learning          20    0.9344     0.9395  0.9344   \n",
              "9    TLKM      Deep Learning          50    0.9016     0.9145  0.9016   \n",
              "10   TLKM   Machine Learning           1    0.6393     0.4545  0.6393   \n",
              "11   TLKM   Machine Learning           5    0.6598     0.6933  0.6598   \n",
              "12   TLKM   Machine Learning          10    0.8402     0.7427  0.8402   \n",
              "13   TLKM   Machine Learning          20    0.9221     0.9229  0.9221   \n",
              "14   TLKM   Machine Learning          50    0.9139     0.9166  0.9139   \n",
              "15   TLKM     Ensemble Model           1    0.7500     0.5679  0.7500   \n",
              "16   TLKM     Ensemble Model           5    0.7459     0.6441  0.7459   \n",
              "17   TLKM     Ensemble Model          10    0.7623     0.7717  0.7623   \n",
              "18   TLKM     Ensemble Model          20    0.7623     0.6907  0.7623   \n",
              "19   TLKM     Ensemble Model          50    0.9344     0.9361  0.9344   \n",
              "20   TLKM  Weighted Ensemble           1    0.7500     0.5679  0.7500   \n",
              "21   TLKM  Weighted Ensemble           5    0.7459     0.6465  0.7459   \n",
              "22   TLKM  Weighted Ensemble          10    0.7623     0.7495  0.7623   \n",
              "23   TLKM  Weighted Ensemble          20    0.7623     0.6907  0.7623   \n",
              "24   TLKM  Weighted Ensemble          50    0.9344     0.9361  0.9344   \n",
              "\n",
              "    f1_score  \n",
              "0     0.5012  \n",
              "1     0.5289  \n",
              "2     0.7799  \n",
              "3     0.8679  \n",
              "4     0.9034  \n",
              "5     0.5052  \n",
              "6     0.6359  \n",
              "7     0.9243  \n",
              "8     0.9360  \n",
              "9     0.9052  \n",
              "10    0.5099  \n",
              "11    0.5396  \n",
              "12    0.7855  \n",
              "13    0.9046  \n",
              "14    0.9108  \n",
              "15    0.6464  \n",
              "16    0.6581  \n",
              "17    0.6740  \n",
              "18    0.6897  \n",
              "19    0.9339  \n",
              "20    0.6464  \n",
              "21    0.6596  \n",
              "22    0.6779  \n",
              "23    0.6897  \n",
              "24    0.9339  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the results into a dataframe to check the final results\n",
        "tmp = pd.read_csv(result_file_path)\n",
        "tmp"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc-autonumbering": false,
    "toc-showcode": true,
    "toc-showmarkdowntxt": true,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
